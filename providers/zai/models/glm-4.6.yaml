name: glm-4.6

apis:
  chat_completion:
    api_format: openai
    endpoint: /chat/completions
    context:
      max_input: 200000
      max_output: 128000
    features:
      tool_use: true
      reasoning: false
      structured_output: true
    parameters:
      temperature: 0.7
      max_tokens: 20000
